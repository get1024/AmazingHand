# AI 虚拟鼠标项目设计规范

## 1. 项目概述

利用计算机视觉技术（MediaPipe）捕捉手部关键点，将手势动作转换为操作系统的鼠标事件（移动、点击、拖拽）。

## 2. 交互逻辑设计 (Interaction Logic)

为了解决误触和操作疲劳，我们采用以下逻辑：

| 手势状态 | 触发条件 | 对应鼠标操作 |
|:-------:|:-------:|:----------:|
| 移动模式 (Moving) | 食指向上，中指/无名指/小指弯曲 | 光标跟随食指指尖 (Index Tip) 移动 |
| 点击/拖拽准备 | 拇指与食指指尖距离 < 阈值 (如 30px) | 触发鼠标左键按下 (MouseDown) |
| 释放 (Release) | 拇指与食指指尖距离 > 阈值 | 触发鼠标左键抬起 (MouseUp) |
| 停用 (Idle) | 全手握拳或手离开画面 | 无操作 |

核心算法流程

1. 捕获图像：读取摄像头帧。
2. 手部检测：识别 21 个手部关键点。
3. 获取坐标：提取食指指尖 (ID: 8) 和拇指指尖 (ID: 4) 的坐标。
4. 区域映射：将摄像头画面中的“活动矩形区域”坐标线性映射到“屏幕分辨率”坐标。
5. 平滑处理：计算当前坐标与上一帧坐标的插值，减少抖动。
6. 动作执行：根据手指距离判断是移动还是点击，调用 OS 接口。

## 3. 代码组织结构 (Class Structure)

建议采用面向对象编程 (OOP) 以便于扩展。

### 3.1 `HandDetector` 类

负责所有与 `MediaPipe` 相关的底层操作。

`__init__`: 初始化 MP 模型。

`find_hands(img)`: 处理图像，返回绘制了骨架的图像。

`find_position(img)`: 返回所有关键点的坐标列表 lmList 和边界框。

`fingers_up()`: 返回一个列表（如 `[0, 1, 0, 0, 0]`），表示 5 根手指伸直的状态。

### 3.2 `AiVirtualMouse` 类 (主控制器)

负责逻辑判断和鼠标控制。

- 属性:
  - `frame_reduction`: 活动区域缩减比例（如 100px）。
  - `smoothening`: 平滑系数（如 7）。
  - `w_cam`, `h_cam`: 摄像头分辨率。
  - `w_scr`, `h_scr`: 屏幕分辨率。

- 方法:
  - `run()`: 主循环，包含图像读取、逻辑处理、FPS 计算。
  - `_move_cursor()`: 内部方法，处理坐标转换和平滑移动。
  - `_handle_clicks()`: 内部方法，处理捏合检测和点击/拖拽状态。

## 4. 关键数学接口

### 4.1 坐标插值 (Smoothing)

$$X_{curr} = X_{prev} + (X_{target} - X_{prev}) / Smoothening$$

### 4.2 坐标映射 (Mapping)

使用 `numpy.interp` 将摄像头坐标范围 `[frame_margin, w_cam - frame_margin]` 映射到屏幕 `[0, w_scr]`。

### 4.3 距离计算

使用欧几里得距离计算拇指 (4) 和食指 (8) 的距离：

$$Dist = \sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}$$

## 5. 异常处理与安全

Fail-safe: 设置 `PyAutoGUI` 的 `FAILSAFE` 为 `False`（避免鼠标移动到角落抛出异常），或在代码中处理边界。

Mac 权限: 必须提示用户开启辅助功能权限。